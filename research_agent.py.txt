import requests
from bs4 import BeautifulSoup
from newsapi import NewsApiClient
import os
from config.settings import NEWS_API_KEY, GOOGLE_CSE_ID, GOOGLE_API_KEY

class ResearchAgent:
    def __init__(self):
        self.sources = [
            "https://www.shrm.org",
            "https://www.gartner.com",
            "https://www.mercer.com"
        ]
        self.newsapi = NewsApiClient(api_key=NEWS_API_KEY)
    
    def get_trends(self):
        trends = []
        # Web Scraping
        for source in self.sources:
            try:
                response = requests.get(source + "/hr-trends")
                soup = BeautifulSoup(response.text, 'html.parser')
                articles = soup.find_all('article', class_='trend-item')
                trends.extend([art.h2.text for art in articles[:5]])
            except Exception as e:
                print(f"Error scraping {source}: {str(e)}")
        
        # News API Integration
        news = self.newsapi.get_everything(
            q='HR trends 2025',
            language='en',
            sort_by='relevancy',
            page_size=10
        )
        trends.extend([article['title'] for article in news['articles']])
        
        return list(set(trends))[:10]  # Return unique trends

    def get_keyword_volume(self, keyword):
        # Google Custom Search JSON API
        url = f"https://www.googleapis.com/customsearch/v1?q={keyword}&key={GOOGLE_API_KEY}&cx={GOOGLE_CSE_ID}"
        response = requests.get(url).json()
        return response.get('searchInformation', {}).get('totalResults', 0)
